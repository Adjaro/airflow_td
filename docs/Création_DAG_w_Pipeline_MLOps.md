# üöÄ √âtape 4 :  Pipeline MLOps avec Airflow et Docker

## **Objectif**
L'objectif de cet exercice est de mettre en place un **pipeline MLOps automatis√©** avec **Apache Airflow** et **Docker** pour g√©rer l'entra√Ænement et l'√©valuation d'un mod√®le de classification sur le dataset **Iris**.

Nous allons :

1. **Charger et pr√©traiter les donn√©es** üìä
2. **Entra√Æner un mod√®le RandomForest** üéØ
3. **√âvaluer la performance du mod√®le** üìà
4. **Mettre en place un DAG Airflow pour automatiser ces √©tapes**

---

## üìÇ **Structure du projet**

```plaintext 
mlops/
‚îÇ‚îÄ‚îÄ airflow-docker/
‚îÇ   ‚îú‚îÄ‚îÄ dags/                      # Contient les DAGs (workflow Airflow)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mlops_pipeline.py
‚îÇ   ‚îÇ   ‚îÇ‚îÄ‚îÄ src/                            # Code m√©tier (pr√©traitement, entra√Ænement...)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
‚îÇ   ‚îÇ   ‚îÇ‚îÄ‚îÄ data/                           # Datasets si besoin
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.csv
‚îÇ   ‚îÇ   ‚îÇ‚îÄ‚îÄ models/                         # Stockage des mod√®les entra√Æn√©s
‚îÇ   ‚îú‚îÄ‚îÄ plugins/                   # Plugins Airflow si n√©cessaire
‚îÇ   ‚îú‚îÄ‚îÄ logs/                       # Logs d'ex√©cution
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml          # D√©ploiement Docker
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances

```

---

## **1Ô∏è‚É£ √âtape 1 - Pr√©traitement des donn√©es**
**üìå Objectif :** Charger et nettoyer les donn√©es Iris, puis les sauvegarder.

üìç **Fichier : `src/preprocessing.py`**
```python {.copy}
import os
import pandas as pd
from sklearn.datasets import load_iris

def preprocess_data():
    print("Pr√©traitement des donn√©es...")

    data_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "../data"))
    os.makedirs(data_dir, exist_ok=True)

    # Charger le dataset Iris
    iris = load_iris()
    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
    df['target'] = iris.target

    file_path = os.path.join(data_dir, "iris.csv")

    df.to_csv(file_path, index=False)
    print(f"Donn√©es sauvegard√©es : {file_path}")

    return file_path

```

---

## **2Ô∏è‚É£ √âtape 2 - Entra√Ænement du mod√®le**
**üìå Objectif :** Entra√Æner un mod√®le `RandomForestClassifier` et sauvegarder le mod√®le.

üìç **Fichier : `src/training.py`**
```python {.copy}
import os
import pandas as pd
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

def train_model():
    print("Entra√Ænement du mod√®le...")

    data= os.path.abspath(os.path.join(os.path.dirname(__file__), "../data/iris.csv"))

    if not os.path.exists(data):
        raise FileNotFoundError(f"{data} introuvable. Ex√©cute preprocessing.py")

    models_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "../models"))
    os.makedirs(models_dir, exist_ok=True)  

    df = pd.read_csv(data)
    X = df.drop(columns=["target"])
    y = df["target"]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    model_file_path = os.path.join(models_dir, "model.pkl")

    joblib.dump(model, model_file_path)
    print(f"Mod√®le sauvegard√© : {model_file_path}")

```

---

## **3Ô∏è‚É£ √âtape 3 - √âvaluation du mod√®le**
**üìå Objectif :** Calculer la pr√©cision du mod√®le et sauvegarder le score.

üìç **Fichier : `src/evaluation.py`**
```python {.copy}
import os
import pandas as pd
import joblib
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

def evaluate_model():
    print("√âvaluation du mod√®le...")

    data = os.path.abspath(os.path.join(os.path.dirname(__file__), "../data/iris.csv"))
    model = os.path.abspath(os.path.join(os.path.dirname(__file__), "../models/model.pkl"))

    # V√©rifier si les fichiers existent
    if not os.path.exists(data):
        raise FileNotFoundError(f"{data} introuvable. Ex√©cuter preprocessing.py")
    
    if not os.path.exists(model):
        raise FileNotFoundError(f"{model} introuvable. Ex√©cuter train_model.py")

    # Charger les donn√©es
    df = pd.read_csv(data)
    X = df.drop(columns=["target"])
    y = df["target"]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = joblib.load(model)

    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"Pr√©cision du mod√®le : {accuracy:.4f}")

    return accuracy

```

---

## **4Ô∏è‚É£ √âtape 4 - DAG Airflow**
üìç **Fichier : `dags/mlops_pipeline.py`**
```python {.copy}
import logging
from datetime import datetime, timedelta
from airflow.models.dag import DAG
from airflow.operators.python import PythonOperator

from src.preprocessing import preprocess_data
from src.training import train_model
from src.evaluation import evaluate_model


default_args = {
    'owner': 'mlops-airflow',
    'retries': 1,
    'retry_delay': timedelta(minutes=10),
    'start_date': datetime.now(),
}

dag = DAG('mlops_pipeline',
    # √Ä compl√©ter
)

task_1 = PythonOperator(
    # √Ä compl√©ter
)

task_2 = PythonOperator(
    # √Ä compl√©ter
)

task_3 = PythonOperator(
    # √Ä compl√©ter
)

task_1 >> # √Ä compl√©ter 
task_1 << # √Ä compl√©ter
```



??? example "Afficher la solution"
    ```python {.copy}
    import logging
    from datetime import datetime, timedelta
    from airflow.models.dag import DAG
    from airflow.operators.python import PythonOperator

    from src.preprocessing import preprocess_data
    from src.training import train_model
    from src.evaluation import evaluate_model


    default_args = {
        'owner': 'mlops-airflow',
        'retries': 1,
        'retry_delay': timedelta(minutes=10),
        'start_date': datetime.now(),
    }

    dag = DAG('mlops_pipeline',
            default_args=default_args,
            schedule_interval=timedelta(days=1),
            catchup=False
    )

    task_1 = PythonOperator(
        task_id='preprocess_data',
        python_callable=preprocess_data,
        dag=dag
    )

    task_2 = PythonOperator(
        task_id='train_model',
        python_callable=train_model,
        dag=dag
    )

    task_3 = PythonOperator(
        task_id='evaluate_model',
        python_callable=evaluate_model,
        dag=dag
    )

    task_1 >> task_2 >> task_3
    ```

---

## **5Ô∏è‚É£ Lancer le pipeline**
1Ô∏è‚É£ **D√©marrer Airflow avec Docker**

<span style="color:red">Modifier la ligne 71 du `docker-compose.yml` pour ajouter les d√©pendances : :</span>

<span style="color:red">
```yaml {.copy}
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:- pandas requests scikit-learn numpy logging}
```
</span>

```sh  {.copy}
docker-compose up
```

2Ô∏è‚É£ **Acc√©der √† Airflow**

- Ouvrir **http://localhost:8080**
- Activer et ex√©cuter le DAG `mlops_pipeline`

---

## **6Ô∏è‚É£ G√©n√©ration du rapport**

Maintenant qu'on a `accuracy`, nous allons g√©n√©rer un rapport contenant cette m√©trique.

### **üìå Objectif : G√©n√©rer un rapport avec l'accuracy**

üìç **Fichier : `src/generate_report.py`**

```python {.copy}
import os

def generate_report(**kwargs):
    ti = kwargs['ti']  # R√©cup√©rer l'accuracy depuis XCom
    accuracy = ti.xcom_pull(task_ids='evaluate_model', key='accuracy')
    
    if accuracy is None:
        raise ValueError("L'accuracy n'a pas √©t√© trouv√©e dans XCom.")
    
    report_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "../report"))
    os.makedirs(report_dir, exist_ok=True)
    
    report_content = f"""
    # Rapport d'√âvaluation du Mod√®le

    **Accuracy**: {accuracy}
    
    **Commentaire**: Le mod√®le a atteint une accuracy de {accuracy}.
    """
    
    report_path = os.path.join(report_dir, "model_accuracy_report.md")
    with open(report_path, "w") as file:
        file.write(report_content)
    
    return report_path
```
Nous avons ajout√© la g√©n√©ration du rapport, nous devons mettre √† jour le **DAG** pour inclure cette nouvelle t√¢che.

üìç **Fichier : `mlops_pipeline.py`**

```python  {.copy}
from src.generate_report import generate_report

task_4 = PythonOperator(
    # √Ä compl√©ter
)

task_3 >> task_4
```

??? success "Solution compl√®te"
    ```python  {.copy}
    from src.generate_report import generate_report

    task_4 = PythonOperator(
        task_id='generate_report',
        python_callable=generate_report,
        provide_context=True,
        dag=dag
    )

    task_3 >> task_4
    ```


Pour s'assurer `evaluate_model`  envoie correctement l'accuracy et que `task_3` r√©cup√®re bien la valeur transmise, on doit faire certaine modification.

### **üìå Modification de `evaluate_model.py` pour envoyer correctement l'accuracy**

Dans **`src/evaluation.py`**, nous devons nous assurer que l'accuracy est bien stock√©e dans XCom et r√©cup√©rable par les t√¢ches suivantes.

üìç **Fichier : `src/evaluation.py`**
```python  {.copy}
import os
import pandas as pd
import joblib
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

def evaluate_model(**kwargs):
    print("√âvaluation du mod√®le...")

    data = os.path.abspath(os.path.join(os.path.dirname(__file__), "../data/iris.csv"))
    model = os.path.abspath(os.path.join(os.path.dirname(__file__), "../models/model.pkl"))

    # V√©rifier si les fichiers existent
    if not os.path.exists(data):
        raise FileNotFoundError(f"{data} introuvable. Ex√©cuter preprocessing.py")
    
    if not os.path.exists(model):
        raise FileNotFoundError(f"{model} introuvable. Ex√©cuter train_model.py")

    # Charger les donn√©es
    df = pd.read_csv(data)
    X = df.drop(columns=["target"])
    y = df["target"]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = joblib.load(model)

    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"Pr√©cision du mod√®le : {accuracy:.4f}")

    ti = kwargs['ti']  
    ti.xcom_push(key='accuracy', value=accuracy)

    return accuracy
```

### **üìå Modifier `task_3` dans `mlops_pipeline.py` pour recevoir les donn√©es correctement**

Dans **`mlops_pipeline.py`**, nous devons nous assurer que `task_3` (√©valuation) est bien configur√© pour recevoir et transmettre les donn√©es.

üìç **Fichier : `mlops_pipeline.py`**

```python  {.copy}
from src.evaluation import evaluate_model

task_3 = PythonOperator(
    task_id='evaluate_model',
    # √Ä compl√©ter
)
```
??? success "Solution compl√®te"
    ```python  {.copy}
    from src.evaluation import evaluate_model

    task_3 = PythonOperator(
        task_id='evaluate_model',
        python_callable=evaluate_model,
        provide_context=True,  # ‚úÖ Assurer le passage des donn√©es via XCom
        dag=dag
    )
    ```

Une fois ces modifications effectu√©es, `evaluate_model` enverra correctement l'accuracy, et `task_3` r√©cup√©rera et transmettra bien les donn√©es pour `generate_report`.





