# üöÄ √âtape 4 : Cr√©ation d'un pipeline ETL avec Airflow

## üéØ Objectif

Cr√©er un pipeline ETL (Extract, Transform, Load) avec Airflow pour :

1. Extraire des donn√©es de ventes de magasins en France et aux √âtats-Unis.
2. Transformer les donn√©es en convertissant les prix en GBP.
3. Charger les donn√©es transform√©es dans un fichier CSV.
4. G√©n√©rer un rapport consolid√©.

---

## üìö Ressources
- [Documentation officielle d'Airflow](https://airflow.apache.org/docs/)
- [PythonOperator](https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/python.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

---

## üìù √âtapes du TD

### Exercice 1 : Mise en place du pipeline de la France

#### Partie 1 : Extraction des donn√©es pour la France

??? tip "Astuce"
      - Pensez √† bien initialiser le r√©pertoire de donn√©es avec `os.makedirs()`.
      - Les `default_args` sont essentiels pour la configuration du DAG.
      - Utilisez `datetime.now()` pour la date de d√©but.

??? example "Code initial"
    ```python
    from airflow import DAG
    from airflow.operators.python_operator import PythonOperator
    from datetime import datetime, timedelta
    import os

    # Fonction d'extraction des donn√©es pour la France
    def extract_france():
        """Simule l'extraction des donn√©es de ventes en France."""
        return {"ventes": [100, 200, 300]}  # Exemple de donn√©es
    ```

1. Cr√©ez un fichier `etl_ventes_dag.py` dans le dossier `dags` d'Airflow.

2. Compl√©tez le dictionnaire `default_args` avec :
   
      - `owner`: votre nom
      - `retries`: 2
      - `retry_delay`: 10 minutes
      - `start_date`: date actuelle

3. Compl√©tez le code de l'instance DAG avec :
   
      - ID: `etl_ventes_pipeline`
      - Arguments par d√©faut: `default_args=default_args`
      - Description personnalis√©e
      - Intervalle d'ex√©cution : 5 minutes

4. D√©finissez la t√¢che `extract_france_task` avec :
   
      - `task_id='extract_france'`
      - `python_callable=extract_france`
      - `dag=dag`

5. üîç V√©rification :
   
   Lancez le DAG `etl_ventes_pipeline`, double-cliquez sur `extract_france_task` et v√©rifiez les donn√©es extraites dans l'onglet XCom.

??? success "Solution compl√®te"
    ```python
    # Configuration du DAG
    default_args = {
        'owner': 'votre_nom',
        'depends_on_past': False,
        'start_date': datetime(2023, 10, 1),
        'retries': 2,
        'retry_delay': timedelta(minutes=10),
    }

    # Cr√©ation du DAG
    dag = DAG(
        'etl_ventes_pipeline',
        default_args=default_args,
        description='Pipeline ETL pour les donn√©es de vente',
        schedule_interval=timedelta(minutes=5),
        catchup=False,
    )

    # T√¢che d'extraction France
    extract_france_task = PythonOperator(
        task_id='extract_france',
        python_callable=extract_france,
        dag=dag,
    )
    ```

---

#### Partie 2 : Transformation des donn√©es pour la France

??? tip "Astuce"
       - Utilisez la fonction `xcom_pull()` pour r√©cup√©rer les donn√©es de la t√¢che pr√©c√©dente.
       - N'oubliez pas d'activer `provide_context=True` pour acc√©der aux XComs.
       - Les op√©rateurs de d√©pendance `>>` ou `<<` d√©finissent l'ordre d'ex√©cution.

??? example "Code initial"
    ```python
    def transform_france(**context):
        """Transformation des donn√©es France"""
        ventes_france = context['ti'].xcom_pull(task_ids='extract_france')
        return {"region": "France", "total_ventes": sum(ventes_france["ventes"])}
    ```

1. Ajoutez le code de transformation dans le fichier `etl_ventes_dag.py`.

2. Compl√©tez la fonction `transform_france` en utilisant XCom :
   ```python
   ventes_france = context['ti'].xcom_pull(task_ids='extract_france')
   return transformation_ventes(ventes_france, "France")
   ```

3. Compl√©tez la t√¢che `transform_france_task` avec :
   
      - `task_id='transform_france'`
      - `python_callable=transform_france`
      - `provide_context=True`
      - `dag=dag`

4. D√©finissez le flux de donn√©es entre les t√¢ches.

5. üîç V√©rification :
   
   V√©rifiez les donn√©es transform√©es dans l'onglet XCom de la t√¢che `transform_france`.

??? success "Solution compl√®te"
    ```python
    def transform_france(**context):
        """Transformation des donn√©es France"""
        ventes_france = context['ti'].xcom_pull(task_ids='extract_france')
        return {"region": "France", "total_ventes": sum(ventes_france["ventes"])}

    transform_france_task = PythonOperator(
        task_id='transform_france',
        python_callable=transform_france,
        provide_context=True,
        dag=dag,
    )

    # D√©finition du flux
    extract_france_task >> transform_france_task
    ```

---

### Exercice 2 : Mise en place du pipeline pour les USA

#### Partie 1 : Extraction des donn√©es pour les USA

??? tip "Astuce"
       - Suivez la m√™me structure que pour la France.
       - Utilisez une fonction `extract_usa` pour simuler l'extraction des donn√©es.

??? example "Code initial"
    ```python
    def extract_usa():
        """Simule l'extraction des donn√©es de ventes aux USA."""
        return {"ventes": [500, 600, 700]}  # Exemple de donn√©es
    ```

1. D√©finissez la t√¢che `extract_usa_task` avec :
   
      - `task_id='extract_usa'`
      - `python_callable=extract_usa`
      - `dag=dag`

2. üîç V√©rification :
   
   V√©rifiez les donn√©es extraites dans l'onglet XCom de la t√¢che `extract_usa`.

??? success "Solution compl√®te"
    ```python
    # T√¢che d'extraction USA
    extract_usa_task = PythonOperator(
        task_id='extract_usa',
        python_callable=extract_usa,
        dag=dag,
    )
    ```

---

#### Partie 2 : Transformation des donn√©es pour les USA

??? tip "Astuce"
    - Utilisez la m√™me logique que pour la France.
    - Assurez-vous de bien r√©cup√©rer les donn√©es via `xcom_pull`.

??? example "Code initial"
    ```python
    def transform_usa(**context):
        """Transformation des donn√©es USA"""
        ventes_usa = context['ti'].xcom_pull(task_ids='extract_usa')
        return {"region": "USA", "total_ventes": sum(ventes_usa["ventes"])}
    ```

1. Ajoutez la t√¢che `transform_usa_task` avec :
   
      - `task_id='transform_usa'`
      - `python_callable=transform_usa`
      - `provide_context=True`
      - `dag=dag`

2. D√©finissez le flux de donn√©es entre les t√¢ches.

3. üîç V√©rification :
   
   V√©rifiez les donn√©es transform√©es dans l'onglet XCom de la t√¢che `transform_usa`.

??? success "Solution compl√®te"
    ```python
    def transform_usa(**context):
        """Transformation des donn√©es USA"""
        ventes_usa = context['ti'].xcom_pull(task_ids='extract_usa')
        return {"region": "USA", "total_ventes": sum(ventes_usa["ventes"])}

    transform_usa_task = PythonOperator(
        task_id='transform_usa',
        python_callable=transform_usa,
        provide_context=True,
        dag=dag,
    )

    # D√©finition du flux
    extract_usa_task >> transform_usa_task
    ```

---

### Exercice 3 : Chargement des donn√©es dans un CSV

??? tip "Astuce"
    - Utilisez `pandas` pour cr√©er un DataFrame et sauvegarder les donn√©es dans un fichier CSV.
    - Assurez-vous que le r√©pertoire de sortie existe.

??? example "Code initial"
    ```python
    import pandas as pd

    def load_data(**context):
        """Charge les donn√©es transform√©es dans un fichier CSV."""
        data_france = context['ti'].xcom_pull(task_ids='transform_france')
        data_usa = context['ti'].xcom_pull(task_ids='transform_usa')
        df = pd.DataFrame([data_france, data_usa])
        df.to_csv('output/ventes.csv', index=False)
    ```

1. Ajoutez la t√¢che `load_data_task` avec :
   
      - `task_id='load_data'`
      - `python_callable=load_data`
      - `provide_context=True`
      - `dag=dag`

2. D√©finissez le flux de donn√©es entre les t√¢ches.

3. üîç V√©rification :
   
   V√©rifiez que le fichier `output/ventes.csv` est cr√©√© avec les donn√©es correctes.

??? success "Solution compl√®te"
    ```python
    def load_data(**context):
        """Charge les donn√©es transform√©es dans un fichier CSV."""
        data_france = context['ti'].xcom_pull(task_ids='transform_france')
        data_usa = context['ti'].xcom_pull(task_ids='transform_usa')
        df = pd.DataFrame([data_france, data_usa])
        os.makedirs('output', exist_ok=True)
        df.to_csv('output/ventes.csv', index=False)

    load_data_task = PythonOperator(
        task_id='load_data',
        python_callable=load_data,
        provide_context=True,
        dag=dag,
    )

    # D√©finition du flux
    [transform_france_task, transform_usa_task] >> load_data_task
    ```

---

### Exercice 4 : Cr√©ation du rapport

??? tip "Astuce"
    - Utilisez `pandas` pour g√©n√©rer un rapport consolid√©.
    - Ajoutez des calculs suppl√©mentaires comme la moyenne ou le total des ventes.

??? example "Code initial"
    ```python
    def generate_report(**context):
        """G√©n√®re un rapport consolid√©."""
        df = pd.read_csv('output/ventes.csv')
        total_ventes = df['total_ventes'].sum()
        moyenne_ventes = df['total_ventes'].mean()
        rapport = f"Total des ventes : {total_ventes}\nMoyenne des ventes : {moyenne_ventes}"
        return rapport
    ```

1. Ajoutez la t√¢che `generate_report_task` avec :
   
      - `task_id='generate_report'`
      - `python_callable=generate_report`
      - `provide_context=True`
      - `dag=dag`

2. D√©finissez le flux de donn√©es entre les t√¢ches.

3. üîç V√©rification :
   
   V√©rifiez que le rapport est g√©n√©r√© correctement.

??? success "Solution compl√®te"
    ```python
    def generate_report(**context):
        """G√©n√®re un rapport consolid√©."""
        df = pd.read_csv('output/ventes.csv')
        total_ventes = df['total_ventes'].sum()
        moyenne_ventes = df['total_ventes'].mean()
        rapport = f"Total des ventes : {total_ventes}\nMoyenne des ventes : {moyenne_ventes}"
        return rapport

    generate_report_task = PythonOperator(
        task_id='generate_report',
        python_callable=generate_report,
        provide_context=True,
        dag=dag,
    )

    # D√©finition du flux
    load_data_task >> generate_report_task
    ```

---

## üéâ R√©sultat final

Vous avez maintenant un pipeline ETL complet avec Airflow qui :
1. Extrait les donn√©es de ventes pour la France et les USA.
2. Transforme les donn√©es en calculant le total des ventes.
3. Charge les donn√©es transform√©es dans un fichier CSV.
4. G√©n√®re un rapport consolid√©.